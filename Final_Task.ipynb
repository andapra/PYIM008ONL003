{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Task.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeUofLcEAc5g"
      },
      "source": [
        "**TENSORFLOW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7HyylOCAfAA"
      },
      "source": [
        "! pip -q install imageio\n",
        "! pip -q install scikit-image\n",
        "! pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUDbLQJ6mj73"
      },
      "source": [
        "**Mounting google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snSc0ANNs-jk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "projectPath = r'drive/MyDrive'\n",
        "folderCeleb = os.path.join(projectPath, 'celeba')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKKo8c1mq7F"
      },
      "source": [
        "**importing library and define interpolation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYpZfOAzAvYh"
      },
      "source": [
        "from absl import logging\n",
        "\n",
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "from IPython import display\n",
        "from skimage import transform\n",
        "\n",
        "latent_dim = 128\n",
        "\n",
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)\n",
        "\n",
        "# Simple way to display an image.\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "# Given a set of images, show an animation.\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0uwyjVom5ri"
      },
      "source": [
        "**Set workspace environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zrEzXSuvwL0"
      },
      "source": [
        "data = os.path.join(folderCeleb, 'img_align_celeba')\n",
        "getData = os.listdir(data)[0:1000]\n",
        "getSample = os.path.join(data, getData[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFiNfAwVm_R2"
      },
      "source": [
        "**plot random image file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LAMOkY65XJX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread(getSample)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBkofxbnE_m"
      },
      "source": [
        "**create normalize arr_image and normalize tensorflow dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNW7wREF7MGc"
      },
      "source": [
        "def my_func(arg):\n",
        "  arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
        "  return arg\n",
        "\n",
        "arr_image = []\n",
        "tensor_dataset = []\n",
        "for i in range(0, 100):\n",
        "  getSample = os.path.join(data, getData[i])\n",
        "  an_image = PIL.Image.open(getSample)\n",
        "\n",
        "  # tf input\n",
        "  image_array = np.asarray(an_image)\n",
        "  normalize = [255]\n",
        "  normalzaArray = np.divide(image_array, normalize)\n",
        "  arr_image.append(normalzaArray)\n",
        "\n",
        "  # tf output\n",
        "  resize_image = an_image.resize((128,128))\n",
        "  image_array = np.asarray(resize_image)\n",
        "  normalize = [255]\n",
        "  normalzaArray = np.divide(image_array, normalize)\n",
        "  change2tensor = my_func(normalzaArray)\n",
        "  tensor_dataset.append(change2tensor)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bAPqAH8nP9e"
      },
      "source": [
        "**plot 100 images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG6o4cjj76Nf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkSbVAHZ54zn"
      },
      "source": [
        "fig = plt.figure(figsize=(20., 20.))\n",
        "grid = ImageGrid(fig, 111, \n",
        "                 nrows_ncols=(10, 10),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, arr_image):\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDE31uKnXa1"
      },
      "source": [
        "**interpolate vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MytKQVOKBFtj"
      },
      "source": [
        "def interpolate_between_vectors():\n",
        "  v1 = tf.random.normal([latent_dim])\n",
        "  v2 = tf.random.normal([latent_dim])\n",
        "  vectors = interpolate_hypersphere(v1, v2, 128)\n",
        "\n",
        "  interpolated_images = tensor_dataset\n",
        "\n",
        "  return interpolated_images\n",
        "\n",
        "interpolated_images = interpolate_between_vectors()\n",
        "animate(interpolated_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3rigoOWndNw"
      },
      "source": [
        "**set target image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InmjIFf6BIyE"
      },
      "source": [
        "image_from_module_space = True  # @param { isTemplate:true, type:\"boolean\" }\n",
        "\n",
        "def get_module_space_image():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  images = tensor_dataset[0]\n",
        "  return images\n",
        "\n",
        "def upload_image():\n",
        "  uploaded = files.upload()\n",
        "  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
        "  return transform.resize(image, [128, 128])\n",
        "\n",
        "if image_from_module_space:\n",
        "  target_image = get_module_space_image()\n",
        "else:\n",
        "  target_image = upload_image()\n",
        "\n",
        "display_image(target_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_plxBx9BPy0"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "initial_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAGG34GXnhF7"
      },
      "source": [
        "**create loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d83c-mZBWAl"
      },
      "source": [
        "def find_closest_latent_vector(initial_vector, num_optimization_steps,\n",
        "                               steps_per_image):\n",
        "  images = []\n",
        "  losses = []\n",
        "\n",
        "  vector = tf.Variable(initial_vector)  \n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "  loss_fn = tf.losses.MeanAbsoluteError(reduction=\"sum\")\n",
        "\n",
        "  for step in range(num_optimization_steps):\n",
        "    if (step % 100)==0:\n",
        "      print()\n",
        "    print('.', end='')\n",
        "    with tf.GradientTape() as tape:\n",
        "      image = tensor_dataset[0]\n",
        "      if (step % steps_per_image) == 0:\n",
        "        images.append(image.numpy())\n",
        "      target_image_difference = loss_fn(image, target_image[:,:,:3])\n",
        "      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
        "\n",
        "      loss = target_image_difference + regularizer\n",
        "      losses.append(loss.numpy())\n",
        "    grads = tape.gradient(loss, [vector])\n",
        "    optimizer.apply_gradients(zip(grads, [vector]))\n",
        "\n",
        "  return images, losses\n",
        "\n",
        "\n",
        "num_optimization_steps=200\n",
        "steps_per_image=5\n",
        "images, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vht6M7qon8cL"
      },
      "source": [
        "**plot loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt-tqyZyBYex"
      },
      "source": [
        "plt.plot(loss)\n",
        "plt.ylim([0,max(plt.ylim())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bGQKzMUoACL"
      },
      "source": [
        "**Displaying different**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXKfU_daas2"
      },
      "source": [
        "display_image(np.concatenate([images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}